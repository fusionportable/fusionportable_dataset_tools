{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data_loader.calib.intrinsic_extrinsic_loader import IntrinsicExtrinsicLoader\n",
    "from data_loader.file_loader import FileLoader\n",
    "from data_loader.file_writer import FileWriter\n",
    "from cfg.dataset.cfg_sequence import dataset_sequence_calib_used_dict\n",
    "from tools.utils import *\n",
    "import cv2\n",
    "\n",
    "platform = 'handheld'\n",
    "sequence_name = 'handheld_room00'\n",
    "algorithm = 'fastlio2'\n",
    "\n",
    "##### Set up the output data path\n",
    "dataset_path = '/Rocket_ssd/dataset/data_FusionPortable/sensor_data'\n",
    "calib_data = dataset_sequence_calib_used_dict[sequence_name][1]\n",
    "calib_path = os.path.join(dataset_path, '../calibration_files', calib_data, 'calib')\n",
    "kitti360_path = os.path.join(dataset_path, sequence_name, 'kitti360')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Set up the message topic list for different platforms\n",
    "# Platform\n",
    "if platform == 'handheld':\n",
    "  from cfg.dataset.cfg_handheld import dataset_sensor_frameid_dict\n",
    "  from cfg.dataset.cfg_handheld import dataset_rostopic_msg_frameid_dict\n",
    "elif platform == 'ugv':\n",
    "  from cfg.dataset.cfg_ugv import dataset_sensor_frameid_dict\n",
    "  from cfg.dataset.cfg_ugv import dataset_rostopic_msg_frameid_dict\n",
    "elif platform == 'legged':\n",
    "  from cfg.dataset.cfg_legged import dataset_sensor_frameid_dict\n",
    "  from cfg.dataset.cfg_legged import dataset_rostopic_msg_frameid_dict\n",
    "  if sequence_name == 'legged_grass00':\n",
    "    dataset_sensor_frameid_dict, dataset_rostopic_msg_frameid_dict = \\\n",
    "      filter_sensor('event', dataset_sensor_frameid_dict, dataset_rostopic_msg_frameid_dict)\n",
    "elif platform =='vehicle':\n",
    "  from cfg.dataset.cfg_vehicle import dataset_sensor_frameid_dict\n",
    "  from cfg.dataset.cfg_vehicle import dataset_rostopic_msg_frameid_dict\n",
    "\n",
    "# Algorithm\n",
    "if algorithm == 'r3live':\n",
    "  from cfg.algorithm.cfg_r3live import algorithm_rostopic_msg_frameid_dict\n",
    "elif algorithm == 'fastlio2':\n",
    "  from cfg.algorithm.cfg_fastlio2 import algorithm_rostopic_msg_frameid_dict\n",
    "\n",
    "##### Set up the sensor configuration\n",
    "int_ext_loader = IntrinsicExtrinsicLoader(is_print=False)\n",
    "int_ext_loader.load_calibration(calib_path=calib_path, sensor_frameid_dict=dataset_sensor_frameid_dict)\n",
    "print('Finish loading calibration parameters')\n",
    "\n",
    "data_path = os.path.join(dataset_path, sequence_name, 'raw_data')\n",
    "alg_result_path = os.path.join(dataset_path, sequence_name, 'algorithm_result')\n",
    "file_loader = FileLoader()\n",
    "file_writer = FileWriter()\n",
    "\n",
    "##### Create the output data path\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'calibration'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'ouster00_undistort/points/data'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'ouster00/points/data'))\n",
    "if platform == 'vehicle':\n",
    "  flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'vehicle_frame_cam00/image/data'))\n",
    "  flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'vehicle_frame_cam01/image/data'))\n",
    "else:\n",
    "  flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'frame_cam00/image/data'))\n",
    "  flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'frame_cam01/image/data'))\n",
    "\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'event_cam00/image/data'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'event_cam00/event/data'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'event_cam00/event_render/data'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'event_cam01/image/data'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'event_cam01/event/data'))\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'event_cam01/event_render/data'))\n",
    "\n",
    "flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'odometry_alg'))\n",
    "\n",
    "if algorithm == 'r3live':\n",
    "  flag = os.system('mkdir -p '+ os.path.join(kitti360_path, 'camera_odometry_alg'))\n",
    "print('Finish creating Folder')\n",
    "\n",
    "##### Visualize TF-tree\n",
    "int_ext_loader.tf_graph.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save calibration files according to KITTI format\n",
    "calib_file_path = os.path.join(kitti360_path, 'calibration', 'perspective.txt')\n",
    "file_writer.write_kitti_calibration_camera_intrinsics(platform, int_ext_loader, calib_file_path)\n",
    "calib_file_path = os.path.join(kitti360_path, 'calibration', 'calib_cam_to_pose.txt')\n",
    "file_writer.write_kitti_calibration_camera_extrinsics(platform, int_ext_loader, calib_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Parameters\n",
    "t_add = 0.1 # the timestamp of the ouster00_undistorted is at the time of the last point approximate to 0.08s\n",
    "\n",
    "##### Load timestamp from alg_result\n",
    "# Ouster\n",
    "if 'ouster_points' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "  ouster_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'ouster00/points/timestamps.txt')) \n",
    "  print('Loading ouster_timestamps: {}'.format(len(ouster_timestamps)))\n",
    "\n",
    "##### Load timestamp from raw_data\n",
    "# Ouster_undistort at the ouster00 frame\n",
    "if 'ouster_points_undistorted' in algorithm_rostopic_msg_frameid_dict.keys():\n",
    "  ouster_un_timestamps = file_loader.load_timestamp(os.path.join(alg_result_path, 'ouster00_undistort/points/timestamps.txt'))\n",
    "  print('Loading ouster_un_timestamps: {}'.format(len(ouster_un_timestamps)))\n",
    "\n",
    "# Frame_camera\n",
    "if platform =='vehicle':\n",
    "  if 'vehicle_frame_left_image' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "    frame_left_image_timestamps = file_loader.load_timestamp(os.path.join(data_path,'vehicle_frame_cam00/image/timestamps.txt'))\n",
    "    print('Loading vehicle_left_timestamps: {}'.format(len(frame_left_image_timestamps)))\n",
    "  if 'vehicle_frame_right_image' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "    frame_right_image_timestamps = file_loader.load_timestamp(os.path.join(data_path,'vehicle_frame_cam01/image/timestamps.txt'))\n",
    "    print('Loading vehicle_right_timestamps: {}'.format(len(frame_right_image_timestamps)))\n",
    "else:\n",
    "  if 'frame_left_image' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "    frame_left_image_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'frame_cam00/image/timestamps.txt'))\n",
    "    print('Loading frame_left_timestamps: {}'.format(len(frame_left_image_timestamps)))\n",
    "  if 'frame_right_image' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "    frame_right_image_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'frame_cam01/image/timestamps.txt'))\n",
    "    print('Loading frame_right_timestamps: {}'.format(len(frame_right_image_timestamps)))\n",
    "    \n",
    "# Event_camera\n",
    "if 'event_left_image' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "  event_left_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'event_cam00/event/timestamps.txt'))\n",
    "  print('Loading event_left_timestamps: {}'.format(len(event_left_timestamps)))\n",
    "  event_left_image_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'event_cam00/image/timestamps.txt'))\n",
    "  print('Loading event_left_image_timestamps: {}'.format(len(event_left_image_timestamps)))\n",
    "else:\n",
    "  event_left_timestamps = []\n",
    "  event_left_image_timestamps = []\n",
    "\n",
    "if 'event_right_image' in dataset_rostopic_msg_frameid_dict.keys():\n",
    "  event_right_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'event_cam01/event/timestamps.txt'))\n",
    "  print('Loading event_right_timestamps: {}'.format(len(event_right_timestamps)))\n",
    "  event_right_image_timestamps = file_loader.load_timestamp(os.path.join(data_path, 'event_cam01/image/timestamps.txt'))\n",
    "  print('Loading event_right_image_timestamps: {}'.format(len(event_right_image_timestamps)))\n",
    "else:\n",
    "  event_right_timestamps = []\n",
    "  event_right_image_timestamps = []\n",
    "\n",
    "if 'odometry' in algorithm_rostopic_msg_frameid_dict.keys():\n",
    "  odom_timestamps, odom_quats, odom_trans = file_loader.load_odometry(os.path.join(alg_result_path, 'odometry/odometry.txt'), traj_type='TUM')\n",
    "  print('Loading odom_timestamps: {}'.format(len(odom_timestamps)))\n",
    "\n",
    "if 'camera_odometry' in algorithm_rostopic_msg_frameid_dict.keys():\n",
    "  camodom_timestamps, camodom_quats, camodom_trans = file_loader.load_odometry(os.path.join(alg_result_path, 'camera_odometry/odometry.txt'), traj_type='TUM')\n",
    "  print('Loading camodom_timestamps: {}'.format(len(camodom_timestamps)))\n",
    "\n",
    "##### Match synchronized timestamps\n",
    "th_ouster_ousterun = 0.02\n",
    "th_ouster_fc, th_fl_fr = 0.03, 0.03\n",
    "th_ouster_ec, th_el_er = 0.02, 0.02\n",
    "matched_id_ouster_sensors_odom = []\n",
    "\n",
    "for id, time in enumerate(ouster_timestamps):\n",
    "    ouster_un_time, ousterun_id = find_closest_element_sorted(ouster_un_timestamps, time + t_add)\n",
    "    if ousterun_id is None or abs(time + t_add - ouster_un_time) >= th_ouster_ousterun:\n",
    "        continue\n",
    "\n",
    "    odom_time, odom_id = find_closest_element_sorted(odom_timestamps, time)\n",
    "    if odom_id is None or abs(time - odom_time) >= th_ouster_ousterun:\n",
    "        continue\n",
    "\n",
    "    fl_time, fl_id = find_closest_element_sorted(frame_left_image_timestamps, time)\n",
    "    fr_time, fr_id = find_closest_element_sorted(frame_right_image_timestamps, time)\n",
    "    if fl_id is None or fr_id is None or abs(time - fl_time) >= th_ouster_fc or abs(time - fr_time) >= th_ouster_fc or abs(fl_time - fr_time) >= th_fl_fr:\n",
    "        continue\n",
    "\n",
    "    el_img_time, el_img_id = find_closest_element_sorted(event_left_image_timestamps, time)\n",
    "    er_img_time, er_img_id = find_closest_element_sorted(event_right_image_timestamps, time)\n",
    "    if el_img_id is not None and er_img_id is not None:\n",
    "        if abs(time - el_img_time) < th_ouster_fc and abs(time - er_img_time) < th_ouster_fc:\n",
    "            matched_id = [id, ousterun_id, odom_id, fl_id, fr_id, el_img_id, er_img_id]\n",
    "\n",
    "    matched_id_ouster_sensors_odom.append(matched_id)\n",
    "\n",
    "print('Length of matched id (ouster_un - sensors): {}'.format(len(matched_id_ouster_sensors_odom)))\n",
    "print(f'{len(matched_id_ouster_sensors_odom)} x {len(matched_id_ouster_sensors_odom[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Analyze matched timestamps\n",
    "if len(matched_id_ouster_sensors_odom) > 0:\n",
    "  import matplotlib.pyplot as plt\n",
    "  num = [i for i in range(len(matched_id_ouster_sensors_odom))]\n",
    "  ##### Ouster_undistorted\n",
    "  dt_ouster_ousterun = [1e3 * abs(ouster_timestamps[mid[0]] + t_add - ouster_un_timestamps[mid[1]]) for mid in matched_id_ouster_sensors_odom]\n",
    "  plt.plot(num, dt_ouster_ousterun, label='Ouster-OusterUn', marker='o', markersize=2, linestyle='none')\n",
    "  ##### Odometry\n",
    "  # dt_ouster_odo = [1e3 * abs(ouster_timestamps[mid[0]] - odom_timestamps[mid[2]]) for mid in matched_id_ouster_sensors_odom]\n",
    "  # plt.plot(num, dt_ouster_odo, label='Ouster-odo', marker='o', markersize=2, linestyle='none') \n",
    "  ##### Frame camera\n",
    "  dt_ouster_fl = [1e3 * abs(ouster_timestamps[mid[0]] - frame_left_image_timestamps[mid[3]]) for mid in matched_id_ouster_sensors_odom]\n",
    "  plt.plot(num, dt_ouster_fl, label='Ouster-FL', marker='o', markersize=2, linestyle='none')\n",
    "  dt_ouster_fr = [1e3 * abs(ouster_timestamps[mid[0]] - frame_right_image_timestamps[mid[4]]) for mid in matched_id_ouster_sensors_odom]\n",
    "  plt.plot(num, dt_ouster_fr, label='Ouster-FR', marker='o', markersize=2, linestyle='none')\n",
    "  dt_fl_fr = [1e3 * abs(frame_left_image_timestamps[mid[3]] - frame_right_image_timestamps[mid[4]]) for mid in matched_id_ouster_sensors_odom]\n",
    "  plt.plot(num, dt_fl_fr, label='FL-FR', marker='o', markersize=2, linestyle='none')\n",
    "  ##### Event camera\n",
    "  if len(matched_id_ouster_sensors_odom[0]) >= 7:\n",
    "    dt_ouster_el = [1e3 * abs(ouster_timestamps[mid[0]] - event_left_image_timestamps[mid[5]]) for mid in matched_id_ouster_sensors_odom]\n",
    "    plt.plot(num, dt_ouster_el, label='Ouster-EL', marker='*', markersize=2, linestyle='none')\n",
    "    dt_ouster_er = [1e3 * abs(ouster_timestamps[mid[0]] - event_right_image_timestamps[mid[6]]) for mid in matched_id_ouster_sensors_odom]\n",
    "    plt.plot(num, dt_ouster_er, label='Ouster-Er', marker='*', markersize=2, linestyle='none')\n",
    "    dt_el_er = [1e3 * abs(event_left_image_timestamps[mid[5]] - event_right_image_timestamps[mid[6]]) for mid in matched_id_ouster_sensors_odom]\n",
    "    plt.plot(num, dt_el_er, label='EL-ER', marker='d', markersize=2, linestyle='none')\n",
    "\n",
    "  plt.xlabel('Num') \n",
    "  plt.ylabel('Delta Timestamp [ms]')\n",
    "  plt.legend(loc='upper right', bbox_to_anchor=(1.38, 1.02))\n",
    "  plt.grid(True)  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Writing sensor data to files\n",
    "def rewrite_undistort_image(old_path, new_path, camera):\n",
    "  import cv2\n",
    "  img = cv2.imread(old_path)\n",
    "  undistorted_img = camera.undistort(img)\n",
    "  cv2.imwrite(new_path, undistorted_img)\n",
    "  return img, undistorted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ev_img = 0.03  # 30ms\n",
    "\n",
    "def write_timestamps(timestamps, path):\n",
    "\tfile_writer.write_timestamp(timestamps, path)\n",
    "\n",
    "def write_odometry(timestamps, quats, trans, path, traj_type):\n",
    "\tfile_writer.write_odometry(timestamps, quats, trans, path, traj_type)\n",
    "\n",
    "def copy_file(src, dst):\n",
    "\tos.system(f'cp {src} {dst}')\n",
    "\n",
    "def render_events(event_img, event_data, camera, ref_time, dt_ev_img):\n",
    "\tevent_img_raw = np.ones_like(event_img) * 255\n",
    "\tselected_ids = [i for i, timestamp in enumerate(event_data['event_msg_timestamps']) if abs(ref_time - timestamp) <= dt_ev_img]\n",
    "\n",
    "\tfor id in selected_ids:\n",
    "\t\tev_data_path = os.path.join(event_data['path'], f'{id:06d}.txt')\n",
    "\t\tev_data = np.loadtxt(ev_data_path)\n",
    "\t\tfor ev in ev_data:\n",
    "\t\t\tif abs(ref_time - ev[0]) <= dt_ev_img / 2:\n",
    "\t\t\t\tcolor = [255, 0, 0] if ev[3] == 1 else [0, 0, 255] # BGR: blue for positive, red for negative\n",
    "\t\t\t\tevent_img_raw[int(ev[2]), int(ev[1])] = color\n",
    "\t\t\t\tevent_img[int(ev[2]), int(ev[1])] = color\n",
    "\n",
    "\tundistorted_event_img_raw = camera.undistort(event_img_raw)\n",
    "\tundistorted_event_img = camera.undistort(event_img)\n",
    "\n",
    "\treturn undistorted_event_img_raw, undistorted_event_img\n",
    "\n",
    "# Save timestamps\n",
    "write_timestamps([ouster_timestamps[mid[0]] for mid in matched_id_ouster_sensors_odom], os.path.join(kitti360_path, 'ouster00/points/timestamps.txt'))\n",
    "write_timestamps([ouster_un_timestamps[mid[1]] for mid in matched_id_ouster_sensors_odom], os.path.join(kitti360_path, 'ouster00_undistort/points/timestamps.txt'))\n",
    "\n",
    "# Save odometry\n",
    "odom_time = [odom_timestamps[mid[2]] for mid in matched_id_ouster_sensors_odom]\n",
    "odom_q = [odom_quats[mid[2]] for mid in matched_id_ouster_sensors_odom]\n",
    "odom_t = [odom_trans[mid[2]] for mid in matched_id_ouster_sensors_odom]\n",
    "write_odometry(odom_time, odom_q, odom_t, os.path.join(kitti360_path, 'odometry_alg/odometry.txt'), traj_type='KITTI')\n",
    "\n",
    "# Save frame camera timestamps\n",
    "cam_prefix = 'vehicle_' if platform == 'vehicle' else ''\n",
    "write_timestamps([frame_left_image_timestamps[mid[3]] for mid in matched_id_ouster_sensors_odom], os.path.join(kitti360_path, f'{cam_prefix}frame_cam00/image/timestamps.txt'))\n",
    "write_timestamps([frame_right_image_timestamps[mid[4]] for mid in matched_id_ouster_sensors_odom], os.path.join(kitti360_path, f'{cam_prefix}frame_cam01/image/timestamps.txt'))\n",
    "\n",
    "# Save event camera timestamps and render events\n",
    "if event_left_image_timestamps and event_right_image_timestamps:\n",
    "\tfor cam_idx, cam_name in enumerate(['event_cam00', 'event_cam01']):\n",
    "\t\tselect_time = [event_left_image_timestamps[mid[5 + cam_idx]] for mid in matched_id_ouster_sensors_odom]\n",
    "\t\twrite_timestamps(select_time, os.path.join(kitti360_path, f'{cam_name}/image/timestamps.txt'))\n",
    "\t\twrite_timestamps(select_time, os.path.join(kitti360_path, f'{cam_name}/event/timestamps.txt'))\n",
    "\t\twrite_timestamps(select_time, os.path.join(kitti360_path, f'{cam_name}/event_render/timestamps.txt'))\n",
    "\n",
    "# Save sensor data\n",
    "for frame_id, mid in enumerate(matched_id_ouster_sensors_odom):\n",
    "\t# Ouster data\n",
    "\tcopy_file(os.path.join(data_path, 'ouster00/points/data', f'{mid[0]:06d}.pcd'), os.path.join(kitti360_path, 'ouster00/points/data', f'{frame_id:06d}.pcd'))\n",
    "\tcopy_file(os.path.join(alg_result_path, 'ouster00_undistort/points/data', f'{mid[1]:06d}.pcd'), os.path.join(kitti360_path, 'ouster00_undistort/points/data', f'{frame_id:06d}.pcd'))\n",
    "\n",
    "\t# Frame camera data\n",
    "\tfor cam_idx, cam_name in enumerate(['frame_cam00', 'frame_cam01']):\n",
    "\t\tcam_prefix = 'vehicle_' if platform == 'vehicle' else ''\n",
    "\t\tdata_path_src = os.path.join(data_path, f'{cam_prefix}{cam_name}/image/data', f'{mid[3 + cam_idx]:06d}.png')\n",
    "\t\tdata_path_dst = os.path.join(kitti360_path, f'{cam_prefix}{cam_name}/image/data', f'{frame_id:06d}.png')\n",
    "\t\tcamera_type = 'frame_left_camera' if cam_name == 'frame_cam00' else 'frame_right_camera'\n",
    "\t\tcamera = int_ext_loader.sensor_collection[f'{cam_prefix}{camera_type}']\n",
    "\t\trewrite_undistort_image(data_path_src, data_path_dst, camera)\n",
    "\n",
    "\t# Event camera data\n",
    "\tif event_left_image_timestamps and event_right_image_timestamps:\n",
    "\t\tevent_img_timestamps = [event_left_image_timestamps, event_right_image_timestamps]\n",
    "\t\tevent_timestamps = [event_left_timestamps, event_right_timestamps]\n",
    "\t\tfor cam_idx, cam_name in enumerate(['event_cam00', 'event_cam01']):\n",
    "\t\t\t# Event image\n",
    "\t\t\tdata_path_src = os.path.join(data_path, f'{cam_name}/image/data', f'{mid[5 + cam_idx]:06d}.png')\n",
    "\t\t\tdata_path_dst = os.path.join(kitti360_path, f'{cam_name}/image/data', f'{frame_id:06d}.png')\n",
    "\t\t\tcamera_type = 'event_left_camera' if cam_name == 'event_cam00' else 'event_right_camera'\n",
    "\t\t\tcamera = int_ext_loader.sensor_collection[f'{cam_prefix}{camera_type}']\n",
    "\t\t\tevent_img, _ = rewrite_undistort_image(data_path_src, data_path_dst, camera) # return the distorted image\n",
    "\n",
    "\t\t\t# Event rendering\n",
    "\t\t\tref_time = event_img_timestamps[cam_idx][mid[5 + cam_idx]]\n",
    "\t\t\tevent_data = {\n",
    "\t\t\t\t'event_msg_timestamps': event_timestamps[cam_idx],\n",
    "\t\t\t\t'path': os.path.join(data_path, f'{cam_name}/event/data')\n",
    "\t\t\t}\n",
    "\t\t\tevent_img_raw, event_img_render = render_events(event_img, event_data, camera, ref_time, dt_ev_img)\n",
    "\t\t\tcv2.imwrite(os.path.join(kitti360_path, f'{cam_name}/event/data', f'{frame_id:06d}.png'), event_img_raw)\n",
    "\t\t\tcv2.imwrite(os.path.join(kitti360_path, f'{cam_name}/event_render/data', f'{frame_id:06d}.png'), event_img_render)\n",
    "\n",
    "print('Finish writing sensor data to kitti360-type dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Generate depth map\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cmap = plt.get_cmap('jet')\n",
    "cmap_colors = cmap(np.linspace(0, 1, 21)) * 255\n",
    "\n",
    "frame_id = 0\n",
    "##### Load point cloud and image\n",
    "pcd_path = os.path.join(kitti360_path, 'ouster00_undistort/points/data', '{:06d}.pcd'.format(frame_id))\n",
    "xyz_points = np.asarray(o3d.io.read_point_cloud(pcd_path).points)\n",
    "\n",
    "if platform == 'vehicle':\n",
    "  # images are already undistorted, but not rectified\n",
    "  img_path = os.path.join(kitti360_path, 'vehicle_frame_cam00', 'image/data', '{:06d}.png'.format(frame_id)) \n",
    "  img = cv2.imread(img_path)\n",
    "  camera = int_ext_loader.sensor_collection['vehicle_frame_left_camera']\n",
    "else:\n",
    "  # images are already undistorted, but not rectified\n",
    "  img_path = os.path.join(kitti360_path, 'frame_cam00', 'image/data', '{:06d}.png'.format(frame_id)) \n",
    "  img = cv2.imread(img_path)\n",
    "  camera = int_ext_loader.sensor_collection['frame_left_camera']\n",
    "\n",
    "##### Load extrinsics from the tf_graph\n",
    "T_cam_lidar = int_ext_loader.tf_graph.get_relative_transform(camera.frame_id, 'body_imu')\n",
    "xyz_points_cam = np.matmul(T_cam_lidar[:3, :3], xyz_points.T).T + T_cam_lidar[:3, 3].T\n",
    "\n",
    "##### Project point cloud onto the camera frame\n",
    "for p_C in xyz_points_cam:\n",
    "  flag, u_C = camera.project(p_C)\n",
    "  if flag:\n",
    "    i = int(min(p_C[2], 20.0))\n",
    "    color = (int(cmap_colors[i, 0]), int(cmap_colors[i, 1]), int(cmap_colors[i, 2]))\n",
    "    cv2.circle(img, (round(u_C[0]), round(u_C[1])), radius=1, color=color, thickness=-1)\n",
    "img_pillow = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "display(img_pillow.resize((img_pillow.size[0] // 2, img_pillow.size[1] // 2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: visualize data\n",
    "from PIL import Image\n",
    "import open3d\n",
    "from tools.utils import display_images_horizontally\n",
    "\n",
    "# Visualize data\n",
    "pcd_path = os.path.join(kitti360_path, 'ouster00_undistort/points/data', '{:06d}.pcd'.format(frame_id))\n",
    "pcd = open3d.io.read_point_cloud(pcd_path)\n",
    "print(pcd.points)\n",
    "\n",
    "pcd_path = os.path.join(kitti360_path, 'ouster00/points/data', '{:06d}.pcd'.format(frame_id))\n",
    "pcd = open3d.io.read_point_cloud(pcd_path)\n",
    "print(pcd.points)\n",
    "\n",
    "if platform == 'vehicle':\n",
    "  img_path = os.path.join(kitti360_path, 'vehicle_frame_cam00', 'image/data', '{:06d}.png'.format(frame_id))\n",
    "  img = Image.open(img_path)\n",
    "  img_fl = img.resize((img.size[0] // 3, img.size[1] // 3))\n",
    "\n",
    "  img_path = os.path.join(kitti360_path, 'vehicle_frame_cam01', 'image/data', '{:06d}.png'.format(frame_id))\n",
    "  img = Image.open(img_path)\n",
    "  img_fr = img.resize((img.size[0] // 3, img.size[1] // 3))\n",
    "else:\n",
    "  img_path = os.path.join(kitti360_path, 'frame_cam00', 'image/data', '{:06d}.png'.format(frame_id))\n",
    "  img = Image.open(img_path)\n",
    "  img_fl = img.resize((img.size[0] // 3, img.size[1] // 3))\n",
    "\n",
    "  img_path = os.path.join(kitti360_path, 'frame_cam01', 'image/data', '{:06d}.png'.format(frame_id))\n",
    "  img = Image.open(img_path)\n",
    "  img_fr = img.resize((img.size[0] // 3, img.size[1] // 3))\n",
    "\n",
    "img_path = os.path.join(kitti360_path, 'event_cam00', 'image/data', '{:06d}.png'.format(frame_id))\n",
    "img = Image.open(img_path)\n",
    "img_el = img.resize((img.size[0], img.size[1]))\n",
    "\n",
    "img_path = os.path.join(kitti360_path, 'event_cam01', 'image/data', '{:06d}.png'.format(frame_id))\n",
    "img = Image.open(img_path)\n",
    "img_er = img.resize((img.size[0], img.size[1]))\n",
    "\n",
    "display_images_horizontally(img_fl, img_fr, img_el, img_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TEST: get extrinsics\n",
    "print(int_ext_loader.tf_graph.get_relative_transform('body_imu', 'ouster00')[:3, :3])\n",
    "print(int_ext_loader.tf_graph.get_relative_transform('body_imu', 'ouster00')[:3, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
